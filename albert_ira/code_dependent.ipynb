{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salsabila.pranida/.conda/envs/ai_aes/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CUDA configuration for better debugging\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 16:47:44.551242: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732106864.565465 1730517 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732106864.569844 1730517 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-20 16:47:44.583846: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../\n",
      "Directory already exists: ../dataset\n",
      "Directory already exists: ../result\n",
      "Directory already exists: ../word_embeddings\n",
      "Directory already exists: ../word_embeddings\n"
     ]
    }
   ],
   "source": [
    "# Define Constants\n",
    "BASE_DIR = '../'  # Root directory for accessing files\n",
    "DATASET_DIR = os.path.join(BASE_DIR, 'dataset')\n",
    "SAVE_DIR = os.path.join(BASE_DIR, 'result')\n",
    "MODEL_NAME = \"albert-base-v2\"  # ALBERT model identifier\n",
    "GLOVE_PATH = os.path.join(BASE_DIR, 'word_embeddings/glove.6B.300d.txt')\n",
    "FASTTEXT_PATH = os.path.join(BASE_DIR, 'word_embeddings/wiki.en.vec')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
    "\n",
    "# Load Tokenizer and ALBERT model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "albert_model = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
    "\n",
    "# Ensure directories exist\n",
    "directories = [BASE_DIR, DATASET_DIR, SAVE_DIR, os.path.dirname(GLOVE_PATH), os.path.dirname(FASTTEXT_PATH)]\n",
    "for directory in directories:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory created: {directory}\")\n",
    "    else:\n",
    "        print(f\"Directory already exists: {directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_model(glove_file_path):\n",
    "    \"\"\"\n",
    "    Load GloVe embeddings into a dictionary.\n",
    "    :param glove_file_path: Path to the GloVe embedding file.\n",
    "    :return: Dictionary with word-to-vector mappings.\n",
    "    \"\"\"\n",
    "    embedding_dict = {}\n",
    "    with open(glove_file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = torch.tensor(np.asarray(values[1:], dtype='float32'))\n",
    "            embedding_dict[word] = vector.to(device)\n",
    "    return embedding_dict\n",
    "\n",
    "def load_fasttext_model(fasttext_file_path):\n",
    "    \"\"\"\n",
    "    Load FastText embeddings into a dictionary.\n",
    "    :param fasttext_file_path: Path to the FastText embedding file.\n",
    "    :return: Dictionary with word-to-vector mappings.\n",
    "    \"\"\"\n",
    "    model = KeyedVectors.load_word2vec_format(fasttext_file_path, binary=False)\n",
    "    return {word: torch.tensor(model[word]).to(device) for word in model.index_to_key}\n",
    "\n",
    "# Load embeddings\n",
    "glove_model = load_glove_model(GLOVE_PATH)\n",
    "fasttext_model = load_fasttext_model(FASTTEXT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>essay_type</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>content</th>\n",
       "      <th>organization</th>\n",
       "      <th>word_choice</th>\n",
       "      <th>sentence_fluency</th>\n",
       "      <th>conventions</th>\n",
       "      <th>language</th>\n",
       "      <th>prompt_adherence</th>\n",
       "      <th>narrativity</th>\n",
       "      <th>style</th>\n",
       "      <th>voice</th>\n",
       "      <th>normalized_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3573</th>\n",
       "      <td>5978</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting affect the cyclist...</td>\n",
       "      <td>dependent</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3574</th>\n",
       "      <td>5979</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting affected the cycli...</td>\n",
       "      <td>dependent</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id  essay_set                                              essay  \\\n",
       "3573      5978          3  The features of the setting affect the cyclist...   \n",
       "3574      5979          3  The features of the setting affected the cycli...   \n",
       "\n",
       "     essay_type  domain1_score  content  organization  word_choice  \\\n",
       "3573  dependent            1.0      0.0           0.0          0.0   \n",
       "3574  dependent            2.0      3.0           0.0          0.0   \n",
       "\n",
       "      sentence_fluency  conventions  language  prompt_adherence  narrativity  \\\n",
       "3573               0.0          0.0       1.0               0.0          1.0   \n",
       "3574               0.0          0.0       2.0               3.0          2.0   \n",
       "\n",
       "      style  voice  normalized_score  \n",
       "3573    0.0    0.0         33.333333  \n",
       "3574    0.0    0.0         66.666667  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and preprocess the dataset\n",
    "df = pd.read_csv('processed_essay_dataset.csv', sep=',', encoding='ISO-8859-1')\n",
    "df = df.dropna(subset=['language', 'prompt_adherence', 'narrativity'])  # Ensure all required columns are present\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5303"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Language': {2.0: 2014, 1.0: 1453, 0.0: 887, 3.0: 821, 4.0: 128}, 'Prompt Adherence': {2.0: 1875, 1.0: 1472, 0.0: 1012, 3.0: 825, 4.0: 119}, 'Narrativity': {2.0: 2117, 1.0: 1421, 0.0: 918, 3.0: 749, 4.0: 98}}\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check unique values\n",
    "print({\n",
    "    \"Language\": df['language'].value_counts().to_dict(),\n",
    "    \"Prompt Adherence\": df['prompt_adherence'].value_counts().to_dict(),\n",
    "    \"Narrativity\": df['narrativity'].value_counts().to_dict()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['language'] = df['language'].astype(int)  # Convert to integers\n",
    "df['prompt_adherence'] = df['prompt_adherence'].astype(int)\n",
    "df['narrativity'] = df['narrativity'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 3, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 2, 1, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.prompt_adherence.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 3, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.narrativity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskDependent(nn.Module):\n",
    "    \"\"\"\n",
    "    A multitask neural network model for predicting classification scores\n",
    "    for various essay attributes such as language, prompt adherence, etc.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        \"\"\"\n",
    "        Initialize the MultiTaskDependent model.\n",
    "        \"\"\"\n",
    "        super(MultiTaskDependent, self).__init__()\n",
    "        # Shared fully connected layers for feature extraction\n",
    "        self.fc1 = nn.Linear(input_shape, 256)  # First shared dense layer\n",
    "        self.bn1 = nn.BatchNorm1d(256)  # Batch normalization after the first dense layer\n",
    "        self.dropout1 = nn.Dropout(0.5)  # Dropout for regularization after the first dense layer\n",
    "        self.fc2 = nn.Linear(256, 128)  # Second shared dense layer\n",
    "        self.bn2 = nn.BatchNorm1d(128)  # Batch normalization after the second dense layer\n",
    "        self.dropout2 = nn.Dropout(0.5)  # Dropout for regularization after the second dense layer\n",
    "\n",
    "        # Task-specific heads for classification\n",
    "        self.language_head = nn.Linear(128, num_classes['language'])  # Head for 'language'\n",
    "        self.prompt_adherence_head = nn.Linear(128, num_classes['prompt_adherence'])  # Head for 'prompt adherence'\n",
    "        self.narrativity_head = nn.Linear(128, num_classes['narrativity'])  # Head for 'narrativity'\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "        \"\"\"\n",
    "        \n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        language_output = self.language_head(x)\n",
    "        prompt_adherence_output = self.prompt_adherence_head(x)\n",
    "        narrativity_output = self.narrativity_head(x)\n",
    "\n",
    "        return language_output, prompt_adherence_output, narrativity_output\n",
    "\n",
    "    def compute_uncertainty_loss(self, loss_language, loss_prompt_adherence, loss_narrativity):\n",
    "        \"\"\"\n",
    "        Compute dynamically weighted loss using task uncertainty parameters.\n",
    "        :return: Total weighted loss.\n",
    "        \"\"\"\n",
    "        # Dynamic weighting of losses based on task uncertainty\n",
    "        language_precision = torch.exp(-self.task_uncertainty[1])  # Precision for language\n",
    "        prompt_adherence_precision = torch.exp(-self.task_uncertainty[1])  # Precision for word choice\n",
    "        narrativity_precision = torch.exp(-self.task_uncertainty[1])  # Precision for sentence fluency\n",
    "\n",
    "        # Weighted loss computation\n",
    "        loss = (\n",
    "            language_precision * loss_language + self.task_uncertainty[1] +\n",
    "            prompt_adherence_precision * loss_prompt_adherence + self.task_uncertainty[1] +\n",
    "            narrativity_precision * loss_narrativity + self.task_uncertainty[1]\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def compute_loss(self, pred_language, pred_prompt_adherence, pred_narrativity,\n",
    "                     y_language, y_prompt_adherence, y_narrativity):\n",
    "        \"\"\"\n",
    "        Compute the total loss across all tasks using CrossEntropyLoss.\n",
    "        :return: Combined loss.\n",
    "        \"\"\"\n",
    "        criterion = nn.CrossEntropyLoss()  # Standard cross-entropy loss\n",
    "\n",
    "        # Compute individual losses for each task\n",
    "        mse_loss_language = criterion(pred_language, y_language)\n",
    "        mse_loss_prompt_adherence = criterion(pred_prompt_adherence, y_prompt_adherence)\n",
    "        mse_loss_narrativity = criterion(pred_narrativity, y_narrativity)\n",
    "\n",
    "        # Combine losses from all tasks\n",
    "        total_loss = (\n",
    "            mse_loss_language + \n",
    "            mse_loss_prompt_adherence + \n",
    "            mse_loss_narrativity\n",
    "        )\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom loss function that incorporates label smoothing into the standard CrossEntropyLoss.\n",
    "    \"\"\"\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "        self.smoothing = smoothing  # Degree of label smoothing\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        \"\"\"\n",
    "        Compute the label-smoothed cross-entropy loss.\n",
    "        :param pred: Predictions (logits) from the model.\n",
    "        :param target: Ground truth labels.\n",
    "        :return: Smoothed cross-entropy loss.\n",
    "        \"\"\"\n",
    "        log_probs = F.log_softmax(pred, dim=-1)  # Convert logits to log probabilities\n",
    "\n",
    "        # Compute negative log likelihood loss\n",
    "        nll_loss = -log_probs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "        nll_loss = nll_loss.squeeze(1)  # Remove extra dimension\n",
    "\n",
    "        # Compute the smoothed loss\n",
    "        smooth_loss = -log_probs.mean(dim=-1)\n",
    "\n",
    "        # Combine the two losses\n",
    "        return (1 - self.smoothing) * nll_loss + self.smoothing * smooth_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_albert_embedding(text):\n",
    "    \"\"\"\n",
    "    Generate ALBERT embeddings for a given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input text.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The embedding vector from ALBERT's last hidden state.\n",
    "    \"\"\"\n",
    "    # Tokenize the input text and send to the device (CPU/GPU)\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=256).to(device)\n",
    "    \n",
    "    # Generate embeddings without computing gradients\n",
    "    with torch.no_grad():\n",
    "        outputs = albert_model(**inputs)\n",
    "    \n",
    "    # Extract the [CLS] token embedding from the last hidden state\n",
    "    return outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "def get_word_embedding(text, embedding_dict):\n",
    "    \"\"\"\n",
    "    Generate word embeddings for a given text using a pre-trained embedding dictionary.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input text.\n",
    "        embedding_dict (dict): Pre-trained word embedding dictionary (e.g., GloVe or FastText).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The average word embedding vector for the input text.\n",
    "    \"\"\"\n",
    "    # Split text into words and fetch embeddings for each word if available\n",
    "    words = text.lower().split()\n",
    "    vectors = [embedding_dict[word] for word in words if word in embedding_dict]\n",
    "    \n",
    "    # Compute the average embedding if vectors are found; otherwise return a zero vector\n",
    "    if vectors:\n",
    "        return torch.mean(torch.stack(vectors), dim=0).cpu().numpy()\n",
    "    return np.zeros(300)  # Default to 300 dimensions\n",
    "\n",
    "def create_attention_based_embedding(albert_emb, additional_emb):\n",
    "    \"\"\"\n",
    "    Create an attention-based fused embedding from ALBERT and additional embeddings.\n",
    "\n",
    "    Args:\n",
    "        albert_emb (torch.Tensor): ALBERT embedding vector.\n",
    "        additional_emb (torch.Tensor): Additional embedding vector (e.g., GloVe or FastText).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Fused embedding based on learned attention weights.\n",
    "    \"\"\"\n",
    "    # Ensure both embeddings have the same shape\n",
    "    if albert_emb.shape != additional_emb.shape:\n",
    "        additional_emb = torch.nn.Linear(additional_emb.shape[0], albert_emb.shape[0]).to(albert_emb.device)(additional_emb)\n",
    "    \n",
    "    # Combine embeddings into a tensor stack\n",
    "    combined_emb = torch.cat([albert_emb.unsqueeze(0), additional_emb.unsqueeze(0)], dim=0)\n",
    "    \n",
    "    # Learn attention weights dynamically\n",
    "    attention_weights = torch.nn.Parameter(torch.tensor([0.5, 0.5], device=albert_emb.device), requires_grad=True)\n",
    "    attention_scores = F.softmax(attention_weights, dim=0)\n",
    "    \n",
    "    # Compute the fused embedding as a weighted sum\n",
    "    fused_embedding = attention_scores[0] * albert_emb + attention_scores[1] * additional_emb\n",
    "    return fused_embedding\n",
    "\n",
    "def create_combined_embedding(text, embedding_type=None, _glove_model=None, _fasttext_model=None):\n",
    "    \"\"\"\n",
    "    Generate a combined embedding by fusing ALBERT and an additional embedding (GloVe/FastText).\n",
    "\n",
    "    Returns:\n",
    "        tuple: Combined embedding as a numpy array and its size.\n",
    "    \"\"\"\n",
    "    # Get ALBERT embedding\n",
    "    albert_emb = get_albert_embedding(text).flatten()\n",
    "\n",
    "    # Get the additional embedding based on the specified type\n",
    "    if embedding_type == \"glove\":\n",
    "        additional_emb = get_word_embedding(text, _glove_model)\n",
    "    elif embedding_type == \"fasttext\":\n",
    "        additional_emb = get_word_embedding(text, _fasttext_model)\n",
    "    else:\n",
    "        additional_emb = np.array([])\n",
    "\n",
    "    # Convert ALBERT embedding to tensor\n",
    "    albert_emb_tensor = torch.tensor(albert_emb, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Combine ALBERT and additional embeddings, ensuring equal size\n",
    "    if additional_emb.size != 0:\n",
    "        additional_emb_tensor = torch.tensor(additional_emb, dtype=torch.float32).to(device)\n",
    "        if additional_emb_tensor.size(0) > albert_emb_tensor.size(0):\n",
    "            additional_emb_tensor = additional_emb_tensor[:albert_emb_tensor.size(0)]\n",
    "        elif additional_emb_tensor.size(0) < albert_emb_tensor.size(0):\n",
    "            padding_size = albert_emb_tensor.size(0) - additional_emb_tensor.size(0)\n",
    "            additional_emb_tensor = F.pad(additional_emb_tensor, (0, padding_size))\n",
    "        combined_emb = torch.cat([albert_emb_tensor, additional_emb_tensor], dim=0)\n",
    "    else:\n",
    "        combined_emb = albert_emb_tensor\n",
    "\n",
    "    # Return the combined embedding and its size\n",
    "    return combined_emb.cpu().numpy(), combined_emb.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_model(X_train_tensor, y_train_language_tensor, \n",
    "                         y_train_prompt_adherence_tensor, y_train_narrativity_tensor, \n",
    "                         input_shape, save_dir, \n",
    "                         embedding_type=None, epochs=10, batch_size=6, learning_rate=1e-4):\n",
    "    \"\"\"\n",
    "    Trains a multi-task classification model and saves its state and metadata.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: \n",
    "        - model_path (str): Path to the saved model file.\n",
    "        - train_losses (list): List of average training losses for each epoch.\n",
    "    \"\"\"\n",
    "    # Determine the number of classes for each task based on the label tensors\n",
    "    num_classes = {\n",
    "        'language': int(y_train_language_tensor.max().item() + 1),  # Classes for 'language'\n",
    "        'prompt_adherence': int(y_train_prompt_adherence_tensor.max().item() + 1),  # Classes for 'prompt adherence'\n",
    "        'narrativity': int(y_train_narrativity_tensor.max().item() + 1),  # Classes for 'narrativity'\n",
    "    }\n",
    "    \n",
    "    print(\"Number of classes:\", num_classes)\n",
    "\n",
    "    # Initialize the MultiTaskDependent model\n",
    "    model = MultiTaskDependent(input_shape, num_classes).to(device)\n",
    "\n",
    "    # Define an Adam optimizer with weight decay for regularization\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    \n",
    "    # Prepare the DataLoader for batching and shuffling\n",
    "    train_loader = DataLoader(\n",
    "        TensorDataset(\n",
    "            X_train_tensor,\n",
    "            y_train_language_tensor, y_train_prompt_adherence_tensor, \n",
    "            y_train_narrativity_tensor\n",
    "        ),\n",
    "        batch_size=batch_size, shuffle=True  # Shuffle data during training\n",
    "    )\n",
    "    \n",
    "    train_losses = []  # To store average loss per epoch\n",
    "\n",
    "    # Training loop for multiple epochs\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        epoch_loss = 0  # Accumulate epoch loss\n",
    "\n",
    "        # Iterate over each batch in the training DataLoader\n",
    "        for X_batch, y_language_batch, y_prompt_adherence_batch, y_narrativity_batch in train_loader:\n",
    "            # Move the data to the appropriate device (CPU/GPU)\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_language_batch = y_language_batch.to(device)\n",
    "            y_prompt_adherence_batch = y_prompt_adherence_batch.to(device)\n",
    "            y_narrativity_batch = y_narrativity_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()  # Clear gradients from the previous step\n",
    "            \n",
    "            # Forward pass: Get predictions for each task\n",
    "            pred_language, pred_prompt_adherence, pred_narrativity = model(X_batch)\n",
    "\n",
    "            # Compute losses for each task using CrossEntropyLoss\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            loss_language = criterion(pred_language, y_language_batch.long())\n",
    "            loss_prompt_adherence = criterion(pred_prompt_adherence, y_prompt_adherence_batch.long())\n",
    "            loss_narrativity = criterion(pred_narrativity, y_narrativity_batch.long())\n",
    "\n",
    "            # Combine losses from all tasks\n",
    "            total_loss = loss_language + loss_prompt_adherence + loss_narrativity\n",
    "            \n",
    "            # Backward pass: Compute gradients\n",
    "            total_loss.backward()\n",
    "\n",
    "            # Clip gradients to prevent exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "            optimizer.step()  # Update the model parameters\n",
    "\n",
    "            # Accumulate the total loss for the current batch\n",
    "            epoch_loss += total_loss.item()\n",
    "\n",
    "        # Compute and store the average loss for the epoch\n",
    "        avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "        train_losses.append(avg_epoch_loss)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Total Epoch Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "    # Define filenames for saving the model and embedding size metadata\n",
    "    model_filename = f\"albert_dependent_model_{embedding_type or 'albert'}.pth\"  # Model filename\n",
    "    embedding_size_filename = f\"albert_dependent_embedding_size_{embedding_type or 'albert'}.npy\"  # Embedding size filename\n",
    "\n",
    "    # Save the trained model and its metadata\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),  # Save model weights\n",
    "        'input_shape': input_shape,             # Save the input shape for reloading the model\n",
    "        'num_classes': num_classes              # Save number of classes for each task\n",
    "    }, os.path.join(save_dir, model_filename))\n",
    "\n",
    "    # Save the input shape as a separate .npy file\n",
    "    np.save(os.path.join(save_dir, embedding_size_filename), input_shape)\n",
    "\n",
    "    # Return the path to the saved model and the list of average training losses\n",
    "    return os.path.join(save_dir, model_filename), train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_path, X_test_tensor, y_test_language_tensor, \n",
    "                   y_test_prompt_adherence_tensor, y_test_narrativity_tensor, save_dir, model_name):\n",
    "    \"\"\"\n",
    "    Evaluate the trained MultiTaskDependent model on the test data and compute performance metrics.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Kappa scores for the evaluated tasks:\n",
    "        - kappa_language (float): Quadratic weighted Kappa for the 'language' task.\n",
    "        - kappa_prompt_adherence (float): Quadratic weighted Kappa for the 'prompt adherence' task.\n",
    "        - kappa_narrativity (float): Quadratic weighted Kappa for the 'narrativity' task.\n",
    "    \"\"\"\n",
    "    # Load the model checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device)  # Load the checkpoint onto the appropriate device\n",
    "    input_shape = checkpoint['input_shape']  # Input shape used during model training\n",
    "    print(input_shape)  # Debug: Print the input shape\n",
    "    num_classes = checkpoint['num_classes']  # Number of classes for each task\n",
    "    print(num_classes)  # Debug: Print the number of classes for each task\n",
    "\n",
    "    # Initialize the model using the saved configuration\n",
    "    model = MultiTaskDependent(input_shape, num_classes).to(device)  # Load model onto the device\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])  # Load the saved model weights\n",
    "    model.eval()  # Set the model to evaluation mode (disable dropout, etc.)\n",
    "\n",
    "    # Move test data tensors to the appropriate device\n",
    "    X_test_tensor = X_test_tensor.to(device)\n",
    "    y_test_language_tensor = y_test_language_tensor.to(device)\n",
    "    y_test_prompt_adherence_tensor = y_test_prompt_adherence_tensor.to(device)\n",
    "    y_test_narrativity_tensor = y_test_narrativity_tensor.to(device)\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations during evaluation\n",
    "        # Forward pass: Get predictions from the model\n",
    "        pred_language, pred_prompt_adherence, pred_narrativity = model(X_test_tensor)\n",
    "\n",
    "        # Compute Cohen's Kappa score for the attributes\n",
    "        kappa_language = cohen_kappa_score(y_test_language_tensor.cpu().numpy(),\n",
    "            np.argmax(pred_language.cpu().numpy(), axis=1), weights='quadratic'\n",
    "        )\n",
    "        \n",
    "        kappa_prompt_adherence = cohen_kappa_score(y_test_prompt_adherence_tensor.cpu().numpy(),\n",
    "            np.argmax(pred_prompt_adherence.cpu().numpy(), axis=1), weights='quadratic'\n",
    "        )\n",
    "\n",
    "        kappa_narrativity = cohen_kappa_score(y_test_narrativity_tensor.cpu().numpy(),\n",
    "            np.argmax(pred_narrativity.cpu().numpy(), axis=1), weights='quadratic'\n",
    "        )\n",
    "        \n",
    "    # Print evaluation results for debugging or analysis\n",
    "    print(f\"Kappa Language: {kappa_language:.4f}\")\n",
    "    print(f\"Kappa Prompt Adherence: {kappa_prompt_adherence:.4f}\")\n",
    "    print(f\"Kappa Narrativity: {kappa_narrativity:.4f}\")\n",
    "\n",
    "    return kappa_language, kappa_prompt_adherence, kappa_narrativity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: {'language': 5, 'prompt_adherence': 5, 'narrativity': 5}\n",
      "Epoch 1/10, Total Epoch Loss: 4.1325\n",
      "Epoch 2/10, Total Epoch Loss: 3.5547\n",
      "Epoch 3/10, Total Epoch Loss: 3.4231\n",
      "Epoch 4/10, Total Epoch Loss: 3.3228\n",
      "Epoch 5/10, Total Epoch Loss: 3.2579\n",
      "Epoch 6/10, Total Epoch Loss: 3.1994\n",
      "Epoch 7/10, Total Epoch Loss: 3.1945\n",
      "Epoch 8/10, Total Epoch Loss: 3.1549\n",
      "Epoch 9/10, Total Epoch Loss: 3.0842\n",
      "Epoch 10/10, Total Epoch Loss: 3.0906\n",
      "768\n",
      "{'language': 5, 'prompt_adherence': 5, 'narrativity': 5}\n",
      "Kappa Language: 0.7181\n",
      "Kappa Prompt Adherence: 0.7259\n",
      "Kappa Narrativity: 0.6893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurm-salsabila.pranida-52509/ipykernel_1730517/3134016901.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: {'language': 5, 'prompt_adherence': 5, 'narrativity': 5}\n",
      "Epoch 1/10, Total Epoch Loss: 4.1304\n",
      "Epoch 2/10, Total Epoch Loss: 3.5630\n",
      "Epoch 3/10, Total Epoch Loss: 3.3773\n",
      "Epoch 4/10, Total Epoch Loss: 3.2933\n",
      "Epoch 5/10, Total Epoch Loss: 3.1959\n",
      "Epoch 6/10, Total Epoch Loss: 3.1982\n",
      "Epoch 7/10, Total Epoch Loss: 3.1382\n",
      "Epoch 8/10, Total Epoch Loss: 3.1475\n",
      "Epoch 9/10, Total Epoch Loss: 3.1021\n",
      "Epoch 10/10, Total Epoch Loss: 3.1194\n",
      "1068\n",
      "{'language': 5, 'prompt_adherence': 5, 'narrativity': 5}\n",
      "Kappa Language: 0.7388\n",
      "Kappa Prompt Adherence: 0.7562\n",
      "Kappa Narrativity: 0.7212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurm-salsabila.pranida-52509/ipykernel_1730517/3134016901.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: {'language': 5, 'prompt_adherence': 5, 'narrativity': 5}\n",
      "Epoch 1/10, Total Epoch Loss: 4.1176\n",
      "Epoch 2/10, Total Epoch Loss: 3.5626\n",
      "Epoch 3/10, Total Epoch Loss: 3.3746\n",
      "Epoch 4/10, Total Epoch Loss: 3.2955\n",
      "Epoch 5/10, Total Epoch Loss: 3.2837\n",
      "Epoch 6/10, Total Epoch Loss: 3.1598\n",
      "Epoch 7/10, Total Epoch Loss: 3.1793\n",
      "Epoch 8/10, Total Epoch Loss: 3.1612\n",
      "Epoch 9/10, Total Epoch Loss: 3.0859\n",
      "Epoch 10/10, Total Epoch Loss: 3.0518\n",
      "1068\n",
      "{'language': 5, 'prompt_adherence': 5, 'narrativity': 5}\n",
      "Kappa Language: 0.7319\n",
      "Kappa Prompt Adherence: 0.7399\n",
      "Kappa Narrativity: 0.7059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurm-salsabila.pranida-52509/ipykernel_1730517/3134016901.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# Main training and evaluation loop\n",
    "embedding_types = [None, \"glove\", \"fasttext\"]  # List of embedding types to evaluate: ALBERT, GloVe, and FastText\n",
    "all_kappa_scores = []  # Initialize list to store Kappa scores for each model and embedding type\n",
    "\n",
    "for embedding_type in embedding_types:\n",
    "    # Set model_name based on the embedding type (default to 'albert' if None is specified)\n",
    "    model_name = embedding_type or 'albert'\n",
    "\n",
    "    # Generate combined embeddings for the essays using the current embedding type\n",
    "    # The embeddings are created by combining ALBERT with optional GloVe or FastText embeddings\n",
    "    embeddings_and_sizes = df['essay'].apply(\n",
    "        lambda x: create_combined_embedding(\n",
    "            x,\n",
    "            embedding_type=embedding_type,  # Specify the embedding type\n",
    "            _glove_model=glove_model if embedding_type == \"glove\" else None,  # Pass GloVe model if applicable\n",
    "            _fasttext_model=fasttext_model if embedding_type == \"fasttext\" else None  # Pass FastText model if applicable\n",
    "        )\n",
    "    )    \n",
    "    \n",
    "    # Split the combined embeddings and their sizes into separate columns\n",
    "    df['embeddings'], embedding_sizes = zip(*embeddings_and_sizes)\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    # Includes input features (embeddings) and target labels for each task\n",
    "    X_train, X_test, y_train_language, y_test_language, \\\n",
    "    y_train_prompt_adherence, y_test_prompt_adherence, \\\n",
    "    y_train_narrativity, y_test_narrativity = train_test_split(\n",
    "        np.stack(df['embeddings'].values),  # Convert embeddings to a stacked NumPy array\n",
    "        df['language'].values,             # Target labels for 'language'\n",
    "        df['prompt_adherence'].values,     # Target labels for 'prompt adherence'\n",
    "        df['narrativity'].values,          # Target labels for 'narrativity'\n",
    "        test_size=0.2,                     # Use 20% of data for testing\n",
    "        random_state=42                    # Ensure reproducibility of data splits\n",
    "    )\n",
    "\n",
    "    # Convert training data to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_language_tensor = torch.tensor(y_train_language, dtype=torch.long)\n",
    "    y_train_prompt_adherence_tensor = torch.tensor(y_train_prompt_adherence, dtype=torch.long)\n",
    "    y_train_narrativity_tensor = torch.tensor(y_train_narrativity, dtype=torch.long)\n",
    "\n",
    "    # Convert testing data to PyTorch tensors\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_language_tensor = torch.tensor(y_test_language, dtype=torch.long)\n",
    "    y_test_prompt_adherence_tensor = torch.tensor(y_test_prompt_adherence, dtype=torch.long)\n",
    "    y_test_narrativity_tensor = torch.tensor(y_test_narrativity, dtype=torch.long)\n",
    "\n",
    "    # Train and save the model for the current embedding type\n",
    "    model_path, train_losses = train_and_save_model(\n",
    "        X_train_tensor,                     # Training input features\n",
    "        y_train_language_tensor,            # Training labels for 'language'\n",
    "        y_train_prompt_adherence_tensor,    # Training labels for 'prompt adherence'\n",
    "        y_train_narrativity_tensor,         # Training labels for 'narrativity'\n",
    "        X_train_tensor.shape[1],            # Input shape (number of features in embeddings)\n",
    "        SAVE_DIR,                           # Directory to save the trained model\n",
    "        embedding_type                      # Embedding type (for model naming and metadata)\n",
    "    )\n",
    "\n",
    "    # Evaluate the trained model on the test set\n",
    "    # Compute Kappa scores for all tasks: language, prompt adherence, and narrativity\n",
    "    kappa_language, kappa_prompt_adherence, kappa_narrativity = evaluate_model(\n",
    "        model_path,                          # Path to the trained model\n",
    "        X_test_tensor,                       # Test input features\n",
    "        y_test_language_tensor,              # Test labels for 'language'\n",
    "        y_test_prompt_adherence_tensor,      # Test labels for 'prompt adherence'\n",
    "        y_test_narrativity_tensor,           # Test labels for 'narrativity'\n",
    "        SAVE_DIR,                            # Directory for additional outputs (if needed)\n",
    "        model_name                           # Name of the model being evaluated\n",
    "    )\n",
    "\n",
    "    # Append the Kappa scores for each task to the results list for comparison\n",
    "    all_kappa_scores.append([\n",
    "        kappa_language, \n",
    "        kappa_prompt_adherence, \n",
    "        kappa_narrativity\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "    In “Let there be dark,” Paul Bogard talks about the importance of darkness.\n",
    "Darkness is essential to humans. Bogard states, “Our bodies need darkness to produce the hormone melatonin, which keeps certain cancers from developing, and our bodies need darkness for sleep, sleep. Sleep disorders have been linked to diabetes, obesity, cardiovascular disease and depression and recent research suggests are main cause of “short sleep” is “long light.” Whether we work at night or simply take our tablets, notebooks and smartphones to bed, there isn’t a place for this much artificial light in our lives.” (Bogard 2). Here, Bogard talks about the importance of darkness to humans. Humans need darkness to sleep in order to be healthy.\n",
    "Animals also need darkness. Bogard states, “The rest of the world depends on darkness as well, including nocturnal and crepuscular species of birds, insects, mammals, fish and reptiles. Some examples are well known—the 400 species of birds that migrate at night in North America, the sea turtles that come ashore to lay their eggs—and some are not, such as the bats that save American farmers billions in pest control and the moths that pollinate 80% of the world’s flora. Ecological light pollution is like the bulldozer of the night, wrecking habitat and disrupting ecosystems several billion years in the making. Simply put, without darkness, Earth’s ecology would collapse...” (Bogard 2). Here Bogard explains that animals, too, need darkness to survive.\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testContent(content, embedding_type=None, SAVE_DIR=None, glove_model=None, fasttext_model=None):\n",
    "    \"\"\"\n",
    "    Test the model on a single piece of content by generating predictions for multiple attributes.\n",
    "\n",
    "    Parameters:\n",
    "    - content (str): The essay content to evaluate.\n",
    "    - embedding_type (str, optional): Type of embedding to use ('glove', 'fasttext', or None for ALBERT). Defaults to None.\n",
    "    - SAVE_DIR (str): Directory where the model and embedding size files are stored.\n",
    "    - glove_model (dict, optional): Pre-trained GloVe embeddings if 'glove' embedding type is used.\n",
    "    - fasttext_model (dict, optional): Pre-trained FastText embeddings if 'fasttext' embedding type is used.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Predicted scores for the following attributes:\n",
    "        - language_score: Predicted score for the 'language' attribute.\n",
    "        - prompt_adherence_score: Predicted score for the 'word choice' attribute.\n",
    "        - narrativity_score: Predicted score for the 'sentence fluency' attribute.\n",
    "    \"\"\"\n",
    "    # Generate a combined embedding for the content\n",
    "    # Combines ALBERT embeddings with optional GloVe or FastText embeddings if specified\n",
    "    embedding, actual_embedding_size = create_combined_embedding(\n",
    "        content,\n",
    "        embedding_type=embedding_type,\n",
    "        _glove_model=glove_model if embedding_type == \"glove\" else None,\n",
    "        _fasttext_model=fasttext_model if embedding_type == \"fasttext\" else None\n",
    "    )\n",
    "\n",
    "    # Convert the embedding to a PyTorch tensor and add a batch dimension for model input\n",
    "    embedding_tensor = torch.tensor(embedding, dtype=torch.float32).to(device).unsqueeze(0)\n",
    "\n",
    "    # Define file paths for the model and embedding configuration files\n",
    "    model_filename = f\"albert_dependent_model_{embedding_type or 'albert'}.pth\"  # Model filename\n",
    "    model_path = os.path.join(SAVE_DIR, model_filename)  # Full path to the model file\n",
    "    \n",
    "    embedding_size_filename = f\"albert_dependent_embedding_size_{embedding_type or 'albert'}.npy\"  # Embedding size filename\n",
    "    embedding_size_path = os.path.join(SAVE_DIR, embedding_size_filename)  # Full path to embedding size file\n",
    "\n",
    "    # Load the expected embedding size from the configuration file\n",
    "    expected_embedding_size = int(np.load(embedding_size_path))  # Read and convert to integer\n",
    "\n",
    "    # Load the model checkpoint containing the weights and configuration\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    input_shape = checkpoint['input_shape']  # Input size used when training the model\n",
    "    num_classes = checkpoint['num_classes']  # Number of output classes for each task\n",
    "\n",
    "    # Initialize the model using the configuration stored in the checkpoint\n",
    "    model = MultiTaskDependent(input_shape, num_classes).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])  # Load model weights into the initialized model\n",
    "    model.eval()  # Set the model to evaluation mode to disable dropout and other training behaviors\n",
    "\n",
    "    # Resize the input embedding if the current size exceeds the expected size\n",
    "    embedding_resized = embedding_tensor[:, :expected_embedding_size]  # Trim embedding to match model's input size\n",
    "\n",
    "    # Generate predictions using the trained model\n",
    "    with torch.no_grad():  # Disable gradient calculations for inference\n",
    "        # Forward pass through the model\n",
    "        pred_language, pred_prompt_adherence, pred_narrativity = model(embedding_resized)\n",
    "\n",
    "        # Extract the predicted class for each attribute (index of the highest probability)\n",
    "        language_score = torch.argmax(pred_language, dim=1).item() + 1  # Add 1 to convert to 1-based index\n",
    "        prompt_adherence_score = torch.argmax(pred_prompt_adherence, dim=1).item() + 1  # Add 1 to convert to 1-based index\n",
    "        narrativity_score = torch.argmax(pred_narrativity, dim=1).item() + 1  # Add 1 to convert to 1-based index\n",
    "\n",
    "    # Return the predicted scores for the attributes as a tuple\n",
    "    return language_score, prompt_adherence_score, narrativity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Essay Scores for ALBERT:\n",
      "  Language Score: 4.00\n",
      "  Prompt Adherence Score: 4.00\n",
      "  Narrativity Score: 4.00\n",
      "Sample Essay Scores for ALBERT + GloVe:\n",
      "  Language Score: 4.00\n",
      "  Prompt Adherence Score: 4.00\n",
      "  Narrativity Score: 4.00\n",
      "Sample Essay Scores for ALBERT + FastText:\n",
      "  Language Score: 4.00\n",
      "  Prompt Adherence Score: 4.00\n",
      "  Narrativity Score: 4.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurm-salsabila.pranida-52509/ipykernel_1730517/3677097889.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Evaluate a sample essay using different embedding types (ALBERT, ALBERT + GloVe, ALBERT + FastText)\n",
    "and store the results in a dictionary. The evaluation generates scores for the following attributes:\n",
    "language, Word Choice, Sentence Fluency, and Conventions.\n",
    "\n",
    "Returns:\n",
    "    dict: A dictionary with embedding types as keys and scores for each attribute as values.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize an empty dictionary to store results for each embedding type\n",
    "results = {}\n",
    "\n",
    "# Define the embedding types to evaluate\n",
    "embedding_types = [None, \"glove\", \"fasttext\"]\n",
    "\n",
    "# Loop through each embedding type\n",
    "for embedding_type in embedding_types:\n",
    "    # Set a readable name for the embedding type\n",
    "    if embedding_type is None:\n",
    "        embedding_type_name = \"ALBERT\"\n",
    "    elif embedding_type == \"glove\":\n",
    "        embedding_type_name = \"ALBERT + GloVe\"\n",
    "    elif embedding_type == \"fasttext\":\n",
    "        embedding_type_name = \"ALBERT + FastText\"\n",
    "\n",
    "    # Generate predictions for the sample content using the current embedding type\n",
    "    language_score, prompt_adherence_score, narrativity_score = testContent(\n",
    "        content=content,                # Content to evaluate\n",
    "        embedding_type=embedding_type,  # Current embedding type (None, GloVe, or FastText)\n",
    "        SAVE_DIR=SAVE_DIR,              # Directory containing saved model files\n",
    "        glove_model=glove_model,        # Preloaded GloVe embeddings (if applicable)\n",
    "        fasttext_model=fasttext_model   # Preloaded FastText embeddings (if applicable)\n",
    "    )\n",
    "\n",
    "    # Store the results for the current embedding type\n",
    "    try:\n",
    "        results[embedding_type_name] = {\n",
    "            \"Language Score\": float(language_score),  # Convert to float for consistency\n",
    "            \"Prompt Adherence Score\": float(prompt_adherence_score),\n",
    "            \"Narrativity Score\": float(narrativity_score),\n",
    "        }\n",
    "    except ValueError:\n",
    "        # Handle any potential issues in conversion\n",
    "        print(f\"Error: Unable to convert one or more values to float for embedding type: {embedding_type_name}\")\n",
    "        print(f\"Values: {language_score}, {prompt_adherence_score}, {narrativity_score}\")\n",
    "\n",
    "# Display the results for each embedding type\n",
    "for embedding_name, result in results.items():\n",
    "    print(f\"Sample Essay Scores for {embedding_name}:\")\n",
    "    print(f\"  Language Score: {result['Language Score']:.2f}\")  # Format to 2 decimal places\n",
    "    print(f\"  Prompt Adherence Score: {result['Prompt Adherence Score']:.2f}\")\n",
    "    print(f\"  Narrativity Score: {result['Narrativity Score']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_aes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
