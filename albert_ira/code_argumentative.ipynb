{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salsabila.pranida/.conda/envs/ai_aes/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from gensim.models import KeyedVectors\n",
    "# from albert import *\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, cohen_kappa_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 08:51:53.078067: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731646313.091637 3875798 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731646313.095911 3875798 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-15 08:51:53.109174: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../\n",
      "Directory already exists: ../dataset\n",
      "Directory already exists: ../result\n",
      "Directory already exists: ../word_embeddings\n",
      "Directory already exists: ../word_embeddings\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "BASE_DIR = '../'  # Navigate one level up to access directories outside of albert_ira\n",
    "DATASET_DIR = os.path.join(BASE_DIR, 'dataset')\n",
    "SAVE_DIR = os.path.join(BASE_DIR, 'result')\n",
    "MODEL_NAME = \"albert-base-v2\"\n",
    "GLOVE_PATH = os.path.join(BASE_DIR, 'word_embeddings/glove.6B.300d.txt')\n",
    "FASTTEXT_PATH = os.path.join(BASE_DIR, 'word_embeddings/wiki.en.vec')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "albert_model = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
    "\n",
    "directories = [BASE_DIR, DATASET_DIR, SAVE_DIR, os.path.dirname(GLOVE_PATH), os.path.dirname(FASTTEXT_PATH)]\n",
    "\n",
    "for directory in directories:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory created: {directory}\")\n",
    "    else:\n",
    "        print(f\"Directory already exists: {directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_model(glove_file_path):\n",
    "    \"\"\"Load GloVe embeddings from file into a dictionary.\"\"\"\n",
    "    embedding_dict = {}\n",
    "    with open(glove_file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = torch.tensor(np.asarray(values[1:], dtype='float32'))\n",
    "            embedding_dict[word] = vector.to(device)  # Move to device if necessary\n",
    "    return embedding_dict\n",
    "\n",
    "def load_fasttext_model(fasttext_file_path):\n",
    "    \"\"\"Load FastText embeddings from file into a dictionary.\"\"\"\n",
    "    model = KeyedVectors.load_word2vec_format(fasttext_file_path, binary=False)\n",
    "    return {word: torch.tensor(model[word]).to(device) for word in model.index_to_key}\n",
    "\n",
    "# Load embeddings\n",
    "glove_model = load_glove_model(GLOVE_PATH)\n",
    "fasttext_model = load_fasttext_model(FASTTEXT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>essay_type</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>content</th>\n",
       "      <th>organization</th>\n",
       "      <th>word_choice</th>\n",
       "      <th>sentence_fluency</th>\n",
       "      <th>conventions</th>\n",
       "      <th>language</th>\n",
       "      <th>prompt_adherence</th>\n",
       "      <th>narrativity</th>\n",
       "      <th>style</th>\n",
       "      <th>voice</th>\n",
       "      <th>normalized_score</th>\n",
       "      <th>quality_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   essay_type  domain1_score  content  organization  word_choice  \\\n",
       "0           0            8.0      4.0           3.0          3.0   \n",
       "1           0            9.0      4.0           4.0          4.0   \n",
       "2           0            7.0      3.0           3.0          3.0   \n",
       "3           0           10.0      5.0           4.0          5.0   \n",
       "4           0            8.0      4.0           3.0          4.0   \n",
       "\n",
       "   sentence_fluency  conventions  language  prompt_adherence  narrativity  \\\n",
       "0               3.0          3.0       0.0               0.0          0.0   \n",
       "1               3.0          4.0       0.0               0.0          0.0   \n",
       "2               4.0          4.0       0.0               0.0          0.0   \n",
       "3               4.0          4.0       0.0               0.0          0.0   \n",
       "4               4.0          4.0       0.0               0.0          0.0   \n",
       "\n",
       "   style  voice  normalized_score  quality_label  \n",
       "0    0.0    0.0              60.0              1  \n",
       "1    0.0    0.0              70.0              2  \n",
       "2    0.0    0.0              50.0              1  \n",
       "3    0.0    0.0              80.0              2  \n",
       "4    0.0    0.0              60.0              1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and preprocess the dataset\n",
    "df = pd.read_csv('processed_essay_dataset.csv', sep=',', encoding='ISO-8859-1')\n",
    "df = df.dropna(subset=['normalized_score','content', 'organization', 'word_choice', 'sentence_fluency', 'conventions'])  # Ensure all required columns are present\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "q1, q3 = df['normalized_score'].quantile([0.25, 0.75])\n",
    "df['quality_label'] = pd.cut(df['normalized_score'], bins=[-1, q1, q3, 100], labels=[0, 1, 2]).astype(int)\n",
    "df['quality_label'] = df['quality_label'].map({0: 0, 1: 1, 2: 2})\n",
    "\n",
    "# Map essay types as before and filter\n",
    "df['essay_type'] = df['essay_type'].map({'argumentative': 0, 'dependent': 1, 'narrative': 2})\n",
    "df = df[df['essay_type'].isin([0, 1])]\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModel(nn.Module):\n",
    "    \"\"\"A multitask model for predicting scores for multiple features.\"\"\"\n",
    "    def __init__(self, input_shape):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        # Shared layers\n",
    "        self.fc1 = nn.Linear(input_shape, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)  # Batch normalization\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        # # Create separate regression heads for each feature\n",
    "        # self.regression_head = nn.Linear(128, 1)\n",
    "\n",
    "        self.content_head = nn.Linear(128, 1)\n",
    "        self.organization_head = nn.Linear(128, 1)\n",
    "        self.word_choice_head = nn.Linear(128, 1)\n",
    "        self.sentence_fluency_head = nn.Linear(128, 1)\n",
    "        self.conventions_head = nn.Linear(128, 1)\n",
    "\n",
    "        # Optional task uncertainty parameter\n",
    "        self.task_uncertainty = nn.Parameter(torch.tensor([0.0, 0.0]), requires_grad=True)     \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # score_output = self.regression_head(x)\n",
    "\n",
    "        # Output for each feature\n",
    "        content_output = self.content_head(x)\n",
    "        organization_output = self.organization_head(x)\n",
    "        word_choice_output = self.word_choice_head(x)\n",
    "        sentence_fluency_output = self.sentence_fluency_head(x)\n",
    "        conventions_output = self.conventions_head(x)\n",
    "\n",
    "        return content_output, organization_output, word_choice_output, \\\n",
    "            sentence_fluency_output, conventions_output\n",
    "\n",
    "    def compute_uncertainty_loss(self, loss_content, loss_organization, loss_word_choice, loss_sentence_fluency, loss_conventions):\n",
    "        \"\"\"Compute the weighted uncertainty loss for each feature.\"\"\"\n",
    "        content_precision = torch.exp(-self.task_uncertainty[0])\n",
    "        organization_precision = torch.exp(-self.task_uncertainty[1])\n",
    "        word_choice_precision = torch.exp(-self.task_uncertainty[1])\n",
    "        sentence_fluency_precision = torch.exp(-self.task_uncertainty[1])\n",
    "        conventions_precision = torch.exp(-self.task_uncertainty[1])\n",
    "\n",
    "        # Weighted loss calculation\n",
    "        loss = (content_precision * loss_content + self.task_uncertainty[0]) + \\\n",
    "               (organization_precision * loss_organization + self.task_uncertainty[1]) + \\\n",
    "                    (word_choice_precision * loss_word_choice + self.task_uncertainty[1]) + \\\n",
    "                        (sentence_fluency_precision * loss_sentence_fluency + self.task_uncertainty[1]) + \\\n",
    "                            (conventions_precision * loss_conventions + self.task_uncertainty[1])\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def compute_loss(self, pred_content, pred_organization, pred_word_choice, pred_sentence_fluency, pred_conventions,\n",
    "                    y_content, y_organization, y_word_choice, y_sentence_fluency, y_conventions) :\n",
    "\n",
    "        # mse_loss = nn.MSELoss()(pred_score, y_score)\n",
    "        # cross_entropy_loss_quality = nn.CrossEntropyLoss()(pred_quality, y_quality)\n",
    "        # cross_entropy_loss_essay_type = nn.CrossEntropyLoss()(pred_essay_type, y_essay_type)\n",
    "\n",
    "        # MSE loss for the additional attributes\n",
    "        mse_loss_content = nn.MSELoss()(pred_content, y_content)\n",
    "        mse_loss_organization = nn.MSELoss()(pred_organization, y_organization)\n",
    "        mse_loss_word_choice = nn.MSELoss()(pred_word_choice, y_word_choice)\n",
    "        mse_loss_sentence_fluency = nn.MSELoss()(pred_sentence_fluency, y_sentence_fluency)\n",
    "        mse_loss_conventions = nn.MSELoss()(pred_conventions, y_conventions)\n",
    "        # mse_loss_language = nn.MSELoss()(pred_language, y_language)\n",
    "        # mse_loss_prompt_adherence = nn.MSELoss()(pred_prompt_adherence, y_prompt_adherence)\n",
    "        # mse_loss_narrativity = nn.MSELoss()(pred_narrativity, y_narrativity)\n",
    "        # mse_loss_style = nn.MSELoss()(pred_style, y_style)\n",
    "        # mse_loss_voice = nn.MSELoss()(pred_voice, y_voice)\n",
    "\n",
    "        # Sum all the losses for total loss\n",
    "        total_loss = mse_loss_content + mse_loss_organization + mse_loss_word_choice + \\\n",
    "                     mse_loss_sentence_fluency + mse_loss_conventions\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        log_probs = F.log_softmax(pred, dim=-1)\n",
    "        nll_loss = -log_probs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "        nll_loss = nll_loss.squeeze(1)\n",
    "        smooth_loss = -log_probs.mean(dim=-1)\n",
    "        return (1 - self.smoothing) * nll_loss + self.smoothing * smooth_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_albert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=256).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = albert_model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "\n",
    "def get_word_embedding(text, embedding_dict):\n",
    "    words = text.lower().split()\n",
    "    vectors = [embedding_dict[word] for word in words if word in embedding_dict]\n",
    "    if vectors:\n",
    "        return torch.mean(torch.stack(vectors), dim=0).cpu().numpy()\n",
    "    return np.zeros(300)\n",
    "\n",
    "# Create attention-based embedding fusion\n",
    "def create_attention_based_embedding(albert_emb, additional_emb):\n",
    "    if albert_emb.shape != additional_emb.shape:\n",
    "        additional_emb = torch.nn.Linear(additional_emb.shape[0], albert_emb.shape[0]).to(albert_emb.device)(additional_emb)\n",
    "    combined_emb = torch.cat([albert_emb.unsqueeze(0), additional_emb.unsqueeze(0)], dim=0)\n",
    "    attention_weights = torch.nn.Parameter(torch.tensor([0.5, 0.5], device=albert_emb.device), requires_grad=True)\n",
    "    attention_scores = F.softmax(attention_weights, dim=0)\n",
    "    fused_embedding = attention_scores[0] * albert_emb + attention_scores[1] * additional_emb\n",
    "    return fused_embedding\n",
    "\n",
    "def create_combined_embedding(text, embedding_type=None, _glove_model=None, _fasttext_model=None):\n",
    "    albert_emb = get_albert_embedding(text).flatten()\n",
    "\n",
    "    if embedding_type == \"glove\":\n",
    "        additional_emb = get_word_embedding(text, _glove_model)\n",
    "    elif embedding_type == \"fasttext\":\n",
    "        additional_emb = get_word_embedding(text, _fasttext_model)\n",
    "    else:\n",
    "        additional_emb = np.array([])\n",
    "\n",
    "    albert_emb_tensor = torch.tensor(albert_emb, dtype=torch.float32).to(device)\n",
    "\n",
    "    if additional_emb.size != 0:\n",
    "        additional_emb_tensor = torch.tensor(additional_emb, dtype=torch.float32).to(device)\n",
    "        \n",
    "        # Ensure both embeddings have the same size by truncating or padding\n",
    "        if additional_emb_tensor.size(0) > albert_emb_tensor.size(0):\n",
    "            additional_emb_tensor = additional_emb_tensor[:albert_emb_tensor.size(0)]  # Truncate\n",
    "        elif additional_emb_tensor.size(0) < albert_emb_tensor.size(0):\n",
    "            padding_size = albert_emb_tensor.size(0) - additional_emb_tensor.size(0)\n",
    "            additional_emb_tensor = F.pad(additional_emb_tensor, (0, padding_size))  # Pad with zeros\n",
    "\n",
    "        combined_emb = torch.cat([albert_emb_tensor, additional_emb_tensor], dim=0)\n",
    "    else:\n",
    "        combined_emb = albert_emb_tensor\n",
    "\n",
    "    return combined_emb.cpu().numpy(), combined_emb.size(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_model(X_train_tensor, y_train_content_tensor, y_train_organization_tensor, \n",
    "                         y_train_word_choice_tensor, y_train_sentence_fluency_tensor, \n",
    "                         y_train_conventions_tensor, input_shape, save_dir, \n",
    "                         embedding_type=None, epochs=10, batch_size=8, learning_rate=1e-4):\n",
    "\n",
    "    model = MultiTaskModel(input_shape).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(\n",
    "            X_train_tensor, y_train_content_tensor, \n",
    "            y_train_organization_tensor, y_train_word_choice_tensor, \n",
    "            y_train_sentence_fluency_tensor, y_train_conventions_tensor), \n",
    "            batch_size=batch_size, shuffle=True\n",
    "        )\n",
    "    \n",
    "    train_losses = []  # Initialize to store the loss for each epoch\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for X_batch, y_content_batch, y_organization_batch, y_word_choice_batch, y_sentence_fluency_batch, y_conventions_batch in train_loader:\n",
    "            # Move data to device\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_content_batch = y_content_batch.to(device)\n",
    "            y_organization_batch = y_organization_batch.to(device)\n",
    "            y_word_choice_batch = y_word_choice_batch.to(device)\n",
    "            y_sentence_fluency_batch = y_sentence_fluency_batch.to(device)\n",
    "            y_conventions_batch = y_conventions_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Get model predictions\n",
    "            pred_content, pred_organization, pred_word_choice, pred_sentence_fluency, pred_conventions = model(X_batch)\n",
    "\n",
    "            # Compute the losses\n",
    "            mse_loss_content = nn.MSELoss()(pred_content, y_content_batch)\n",
    "            mse_loss_organization = nn.MSELoss()(pred_organization, y_organization_batch)\n",
    "            mse_loss_word_choice = nn.MSELoss()(pred_word_choice, y_word_choice_batch)\n",
    "            mse_loss_sentence_fluency = nn.MSELoss()(pred_sentence_fluency, y_sentence_fluency_batch)\n",
    "            mse_loss_conventions = nn.MSELoss()(pred_conventions, y_conventions_batch)\n",
    "\n",
    "            # Total loss\n",
    "            total_loss = mse_loss_content + mse_loss_organization + mse_loss_word_choice + \\\n",
    "                         mse_loss_sentence_fluency + mse_loss_conventions\n",
    "\n",
    "            total_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "            optimizer.step()\n",
    "            epoch_loss += total_loss.item()\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "        train_losses.append(avg_epoch_loss)  # Append the average epoch loss to train_losses\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Total Epoch Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "    # Save the model\n",
    "    model_filename = f\"albert6_model_{embedding_type or 'albert'}.pth\"\n",
    "    embedding_size_filename = f\"albert6_embedding_size_{embedding_type or 'albert'}.npy\"\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, model_filename))\n",
    "    np.save(os.path.join(save_dir, embedding_size_filename), input_shape)\n",
    "    \n",
    "    return os.path.join(save_dir, model_filename), train_losses  # Return model_path and train_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_path, y_test_content, y_test_organization, y_test_word_choice, y_test_sentence_fluency,\n",
    "                   y_test_conventions, save_dir, model_name):\n",
    "\n",
    "    # Load the model and move it to the appropriate device\n",
    "    model = MultiTaskModel(X_test_tensor.shape[1]).to(device)  # Move model to device\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # Move test tensors to the correct device\n",
    "    y_test_content = y_test_content.to(device)\n",
    "    y_test_organization = y_test_organization.to(device)\n",
    "    y_test_word_choice = y_test_word_choice.to(device)\n",
    "    y_test_sentence_fluency = y_test_sentence_fluency.to(device)\n",
    "    y_test_conventions = y_test_conventions.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get model predictions (all outputs)\n",
    "        pred_content, pred_organization, pred_word_choice, pred_sentence_fluency, pred_conventions = model(X_test_tensor.to(device))\n",
    "\n",
    "        # Kappa scores for each attribute\n",
    "        kappa_content = cohen_kappa_score(y_test_content.cpu().numpy(), np.round(pred_content.cpu().numpy().squeeze()).astype(int), weights='quadratic')\n",
    "        kappa_organization = cohen_kappa_score(y_test_organization.cpu().numpy(), np.round(pred_organization.cpu().numpy().squeeze()).astype(int), weights='quadratic')\n",
    "        kappa_word_choice = cohen_kappa_score(y_test_word_choice.cpu().numpy(), np.round(pred_word_choice.cpu().numpy().squeeze()).astype(int), weights='quadratic')\n",
    "        kappa_sentence_fluency = cohen_kappa_score(y_test_sentence_fluency.cpu().numpy(), np.round(pred_sentence_fluency.cpu().numpy().squeeze()).astype(int), weights='quadratic')\n",
    "        kappa_conventions = cohen_kappa_score(y_test_conventions.cpu().numpy(), np.round(pred_conventions.cpu().numpy().squeeze()).astype(int), weights='quadratic')\n",
    "\n",
    "        # Print out the evaluation results\n",
    "        print(f\"Kappa for Content: {kappa_content:.5f}\")\n",
    "        print(f\"Kappa for Organization: {kappa_organization:.5f}\")\n",
    "        print(f\"Kappa for Word Choice: {kappa_word_choice:.5f}\")\n",
    "        print(f\"Kappa for Sentence Fluency: {kappa_sentence_fluency:.5f}\")\n",
    "        print(f\"Kappa for Conventions: {kappa_conventions:.5f}\")\n",
    "\n",
    "        return kappa_content, kappa_organization, kappa_word_choice, kappa_sentence_fluency, kappa_conventions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for embedding type: albert\n",
      "Epoch 1/10, Total Epoch Loss: 12.4695\n",
      "Epoch 2/10, Total Epoch Loss: 7.6379\n",
      "Epoch 3/10, Total Epoch Loss: 7.4841\n",
      "Epoch 4/10, Total Epoch Loss: 7.2380\n",
      "Epoch 5/10, Total Epoch Loss: 7.1337\n",
      "Epoch 6/10, Total Epoch Loss: 7.0646\n",
      "Epoch 7/10, Total Epoch Loss: 7.0196\n",
      "Epoch 8/10, Total Epoch Loss: 6.9045\n",
      "Epoch 9/10, Total Epoch Loss: 6.8418\n",
      "Epoch 10/10, Total Epoch Loss: 6.7760\n",
      "Kappa for Content: 0.01686\n",
      "Kappa for Organization: 0.02689\n",
      "Kappa for Word Choice: 0.01912\n",
      "Kappa for Sentence Fluency: 0.03552\n",
      "Kappa for Conventions: 0.02673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurm-salsabila.pranida-51373/ipykernel_2337730/2557821399.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for embedding type: glove\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salsabila.pranida/.conda/envs/ai_aes/lib/python3.11/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/salsabila.pranida/.conda/envs/ai_aes/lib/python3.11/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Total Epoch Loss: 13.3931\n",
      "Epoch 2/10, Total Epoch Loss: 7.8071\n",
      "Epoch 3/10, Total Epoch Loss: 7.5703\n",
      "Epoch 4/10, Total Epoch Loss: 7.3461\n",
      "Epoch 5/10, Total Epoch Loss: 7.1659\n",
      "Epoch 6/10, Total Epoch Loss: 7.0112\n",
      "Epoch 7/10, Total Epoch Loss: 6.9268\n",
      "Epoch 8/10, Total Epoch Loss: 6.9814\n",
      "Epoch 9/10, Total Epoch Loss: 6.8266\n",
      "Epoch 10/10, Total Epoch Loss: 6.7712\n",
      "Kappa for Content: -0.08098\n",
      "Kappa for Organization: -0.06112\n",
      "Kappa for Word Choice: -0.06509\n",
      "Kappa for Sentence Fluency: -0.06885\n",
      "Kappa for Conventions: -0.07251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurm-salsabila.pranida-51373/ipykernel_2337730/2557821399.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for embedding type: fasttext\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/salsabila.pranida/.conda/envs/ai_aes/lib/python3.11/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/salsabila.pranida/.conda/envs/ai_aes/lib/python3.11/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Total Epoch Loss: 12.5424\n",
      "Epoch 2/10, Total Epoch Loss: 7.6974\n",
      "Epoch 3/10, Total Epoch Loss: 7.5291\n",
      "Epoch 4/10, Total Epoch Loss: 7.2858\n",
      "Epoch 5/10, Total Epoch Loss: 7.1851\n",
      "Epoch 6/10, Total Epoch Loss: 7.0608\n",
      "Epoch 7/10, Total Epoch Loss: 6.9573\n",
      "Epoch 8/10, Total Epoch Loss: 6.9117\n",
      "Epoch 9/10, Total Epoch Loss: 6.7950\n",
      "Epoch 10/10, Total Epoch Loss: 6.7691\n",
      "Kappa for Content: -0.04745\n",
      "Kappa for Organization: -0.02561\n",
      "Kappa for Word Choice: -0.03016\n",
      "Kappa for Sentence Fluency: -0.07495\n",
      "Kappa for Conventions: -0.04222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurm-salsabila.pranida-51373/ipykernel_2337730/2557821399.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "# Main training and evaluation loop\n",
    "embedding_types = [None, \"glove\", \"fasttext\"]\n",
    "all_train_losses = []  # To store training losses for each embedding type\n",
    "embedding_labels = [embedding_type or 'albert' for embedding_type in embedding_types]\n",
    "all_kappa_scores = []  # Initialize list to store Kappa scores for each model\n",
    "\n",
    "for embedding_type in embedding_types:\n",
    "    # Set model_name based on the embedding type for evaluation\n",
    "    model_name = embedding_type or 'albert'\n",
    "    \n",
    "    embeddings_and_sizes = df['essay'].apply(lambda x: create_combined_embedding(x, embedding_type, glove_model, fasttext_model))\n",
    "    df['embeddings'], embedding_sizes = zip(*embeddings_and_sizes)\n",
    "\n",
    "    embedding_sizes = np.array(embedding_sizes)\n",
    "\n",
    "    X_train, X_test, y_train_content, y_test_content, y_train_organization, y_test_organization, \\\n",
    "    y_train_word_choice, y_test_word_choice, y_train_sentence_fluency, y_test_sentence_fluency, \\\n",
    "    y_train_conventions, y_test_conventions = train_test_split(\n",
    "        np.stack(df['embeddings'].values),\n",
    "        df['content'].values,\n",
    "        df['organization'].values,\n",
    "        df['word_choice'].values,\n",
    "        df['sentence_fluency'].values,\n",
    "        df['conventions'].values,\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Convert each subset to PyTorch tensors for compatibility with the training process\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)  # Reshape for regression target\n",
    "\n",
    "    y_train_content_tensor = torch.tensor(y_train_content, dtype=torch.float32)\n",
    "    y_train_organization_tensor = torch.tensor(y_train_organization, dtype=torch.float32)\n",
    "    y_train_word_choice_tensor = torch.tensor(y_train_word_choice, dtype=torch.float32)\n",
    "    y_train_sentence_fluency_tensor = torch.tensor(y_train_sentence_fluency, dtype=torch.float32)\n",
    "    y_train_conventions_tensor = torch.tensor(y_train_conventions, dtype=torch.float32)\n",
    "\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    y_test_content_tensor = torch.tensor(y_test_content, dtype=torch.float32)\n",
    "    y_test_organization_tensor = torch.tensor(y_test_organization, dtype=torch.float32)\n",
    "    y_test_word_choice_tensor = torch.tensor(y_test_word_choice, dtype=torch.float32)\n",
    "    y_test_sentence_fluency_tensor = torch.tensor(y_test_sentence_fluency, dtype=torch.float32)\n",
    "    y_test_conventions_tensor = torch.tensor(y_test_conventions, dtype=torch.float32)\n",
    "\n",
    "    # Train the model with the current embedding type and save it for future evaluation\n",
    "    print(f\"\\nTraining model for embedding type: {model_name}\")\n",
    "    model_path, _ = train_and_save_model(\n",
    "        X_train_tensor,\n",
    "        y_train_content_tensor,\n",
    "        y_train_organization_tensor,\n",
    "        y_train_word_choice_tensor,\n",
    "        y_train_sentence_fluency_tensor,\n",
    "        y_train_conventions_tensor,\n",
    "        input_shape=X_train_tensor.shape[1],  # Pass as keyword argument\n",
    "        save_dir=SAVE_DIR,\n",
    "        embedding_type=embedding_type,\n",
    "        epochs=10,\n",
    "        batch_size=8,\n",
    "        learning_rate=1e-3\n",
    "    )\n",
    "\n",
    "    # Evaluate the trained model and collect metrics, particularly Kappa scores for each attribute\n",
    "    kappa_content, kappa_organization, kappa_word_choice, kappa_sentence_fluency, kappa_conventions = evaluate_model(\n",
    "        model_path,\n",
    "        y_test_content_tensor, y_test_organization_tensor, y_test_word_choice_tensor, \n",
    "        y_test_sentence_fluency_tensor, y_test_conventions_tensor, SAVE_DIR, model_name\n",
    "    )\n",
    "\n",
    "\n",
    "    # Append Kappa scores for each attribute to all_kappa_scores to plot later\n",
    "    all_kappa_scores.append([kappa_content, kappa_organization, kappa_word_choice, kappa_sentence_fluency, \\\n",
    "        kappa_conventions])\n",
    "\n",
    "# # Plot a heatmap of Kappa scores for each model variant to visualize attribute-level performance\n",
    "# plot_kappa_heatmap(\n",
    "#     all_kappa_scores,\n",
    "#     model_names=['Albert', 'Albert + Glove', 'Albert + Fasttext'],\n",
    "#     attribute_names=[\n",
    "#         'Content', 'Organization', 'Word Choice', 'Sentence Fluency', 'Conventions'\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\"\"\n",
    "    In “Let there be dark,” Paul Bogard talks about the importance of darkness.\n",
    "Darkness is essential to humans. Bogard states, “Our bodies need darkness to produce the hormone melatonin, which keeps certain cancers from developing, and our bodies need darkness for sleep, sleep. Sleep disorders have been linked to diabetes, obesity, cardiovascular disease and depression and recent research suggests are main cause of “short sleep” is “long light.” Whether we work at night or simply take our tablets, notebooks and smartphones to bed, there isn’t a place for this much artificial light in our lives.” (Bogard 2). Here, Bogard talks about the importance of darkness to humans. Humans need darkness to sleep in order to be healthy.\n",
    "Animals also need darkness. Bogard states, “The rest of the world depends on darkness as well, including nocturnal and crepuscular species of birds, insects, mammals, fish and reptiles. Some examples are well known—the 400 species of birds that migrate at night in North America, the sea turtles that come ashore to lay their eggs—and some are not, such as the bats that save American farmers billions in pest control and the moths that pollinate 80% of the world’s flora. Ecological light pollution is like the bulldozer of the night, wrecking habitat and disrupting ecosystems several billion years in the making. Simply put, without darkness, Earth’s ecology would collapse...” (Bogard 2). Here Bogard explains that animals, too, need darkness to survive.\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testContent(content, embedding_type=None, SAVE_DIR=None, glove_model=None, fasttext_model=None):\n",
    "    # Generate the combined embedding\n",
    "    embedding, actual_embedding_size = create_combined_embedding(\n",
    "        content,\n",
    "        embedding_type=embedding_type,\n",
    "        _glove_model=glove_model if embedding_type == \"glove\" else None,\n",
    "        _fasttext_model=fasttext_model if embedding_type == \"fasttext\" else None\n",
    "    )\n",
    "\n",
    "    embedding_tensor = torch.tensor(embedding, dtype=torch.float32).to(device).unsqueeze(0)\n",
    "\n",
    "    # Load model files\n",
    "    embedding_size_filename = f\"albert6_embedding_size_{embedding_type or 'albert'}.npy\"\n",
    "    model_filename = f\"albert6_model_{embedding_type or 'albert'}.pth\"\n",
    "\n",
    "    # Load the expected embedding size and model\n",
    "    embedding_size_path = os.path.join(SAVE_DIR, embedding_size_filename)\n",
    "    expected_embedding_size = int(np.load(embedding_size_path))\n",
    "\n",
    "    # Initialize model and load weights\n",
    "    model = MultiTaskModel(expected_embedding_size).to(device)\n",
    "    model_path = os.path.join(SAVE_DIR, model_filename)\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model.eval()\n",
    "\n",
    "    # Adjust embedding size if necessary\n",
    "    embedding_resized = embedding_tensor[:, :expected_embedding_size]\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        pred_content, pred_organization, pred_word_choice, pred_sentence_fluency, pred_conventions = model(embedding_resized)\n",
    "        content_score = pred_content.cpu().item()\n",
    "        language_score = pred_organization.cpu().item()\n",
    "        prompt_adherence_score = pred_word_choice.cpu().item()\n",
    "        narrativity_score = pred_sentence_fluency.cpu().item()\n",
    "        conventions_score = pred_sentence_fluency.cpu().item()\n",
    "\n",
    "    return content_score, language_score, prompt_adherence_score, narrativity_score, conventions_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurm-salsabila.pranida-51449/ipykernel_3875798/754038271.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Type: ALBERT\n",
      "Returned Values: 3.431947946548462, 3.305612325668335, 3.2921910285949707, 3.3810877799987793, 3.3810877799987793\n",
      "Embedding Type: ALBERT + GloVe\n",
      "Returned Values: 3.2467987537384033, 3.1035304069519043, 3.12103533744812, 3.263153314590454, 3.263153314590454\n",
      "Embedding Type: ALBERT + FastText\n",
      "Returned Values: 3.2504689693450928, 3.059922456741333, 3.1035611629486084, 3.2877790927886963, 3.2877790927886963\n",
      "Sample Essay Scores for ALBERT:\n",
      "  Content Score: 3.43\n",
      "  Organization Score: 3.31\n",
      "  Word Choice Score: 3.29\n",
      "  Sentence Fluency Score: 3.38\n",
      "  Conventions Score: 3.38\n",
      "Sample Essay Scores for ALBERT + GloVe:\n",
      "  Content Score: 3.25\n",
      "  Organization Score: 3.10\n",
      "  Word Choice Score: 3.12\n",
      "  Sentence Fluency Score: 3.26\n",
      "  Conventions Score: 3.26\n",
      "Sample Essay Scores for ALBERT + FastText:\n",
      "  Content Score: 3.25\n",
      "  Organization Score: 3.06\n",
      "  Word Choice Score: 3.10\n",
      "  Sentence Fluency Score: 3.29\n",
      "  Conventions Score: 3.29\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store results for each embedding type\n",
    "results = {}\n",
    "\n",
    "# Define the embedding types\n",
    "embedding_types = [None, \"glove\", \"fasttext\"]\n",
    "\n",
    "for embedding_type in embedding_types:\n",
    "    # Define embedding type name for readability\n",
    "    if embedding_type is None:\n",
    "        embedding_type_name = \"ALBERT\"\n",
    "    elif embedding_type == \"glove\":\n",
    "        embedding_type_name = \"ALBERT + GloVe\"\n",
    "    elif embedding_type == \"fasttext\":\n",
    "        embedding_type_name = \"ALBERT + FastText\"\n",
    "\n",
    "    # Generate the scores for the given content and embedding type\n",
    "    content_score, organization_score, word_choice_score, sentence_fluency_score, conventions_score = testContent(\n",
    "        content=content,\n",
    "        embedding_type=embedding_type,\n",
    "        SAVE_DIR=SAVE_DIR,\n",
    "        glove_model=glove_model,\n",
    "        fasttext_model=fasttext_model\n",
    "    )\n",
    "    print(f\"Embedding Type: {embedding_type_name}\")\n",
    "    print(f\"Returned Values: {content_score}, {organization_score}, {word_choice_score}, {sentence_fluency_score}, {conventions_score}\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        results[embedding_type_name] = {\n",
    "            \"Content Score\": float(content_score),\n",
    "            \"Organization Score\": float(organization_score),\n",
    "            \"Word Choice Score\": float(word_choice_score),\n",
    "            \"Sentence Fluency Score\": float(sentence_fluency_score),\n",
    "            \"Conventions Score\": float(conventions_score)\n",
    "        }\n",
    "    except ValueError:\n",
    "        print(f\"Error: Unable to convert one or more values to float for embedding type: {embedding_type_name}\")\n",
    "        print(f\"Values: {content_score}, {organization_score}, {word_choice_score}, {sentence_fluency_score}, {conventions_score}\")\n",
    "\n",
    "# Display the results for each embedding type\n",
    "for embedding_name, result in results.items():\n",
    "    print(f\"Sample Essay Scores for {embedding_name}:\")\n",
    "    print(f\"  Content Score: {result['Content Score']:.2f}\")\n",
    "    print(f\"  Organization Score: {result['Organization Score']:.2f}\")\n",
    "    print(f\"  Word Choice Score: {result['Word Choice Score']:.2f}\")\n",
    "    print(f\"  Sentence Fluency Score: {result['Sentence Fluency Score']:.2f}\")\n",
    "    print(f\"  Conventions Score: {result['Conventions Score']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_aes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
